# -*- coding: utf-8 -*-
"""최종.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QzKeg_Acww0ktcSIJXNpnKv4xEuUzU2r
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel
from flask import Flask, request, jsonify
import pymysql

tb_keyword = pd.read_csv('file/tb_keyword.csv')
tb_study = pd.read_csv('file/tb_study.csv')
tb_study_keyword = pd.read_csv('file/tb_study_keyword.csv')
tb_study_member = pd.read_csv('file/tb_study_member.csv')
tb_study_review = pd.read_csv('file/tb_study_review.csv')
tb_study_review_keyword = pd.read_csv('file/tb_study_review_keyword.csv')
tb_user = pd.read_csv('file/tb_user.csv')
tb_user_keyword = pd.read_csv('file/tb_user_keyword.csv')

host = 'project-db-campus.smhrd.com'       # MySQL 서버 주소 (로컬일 경우 localhost)
port = 3307              # MySQL 포트 (기본값 3306)
user = 'campus_24K_LI_p2_2'            # MySQL 사용자 계정
password = 'smhrd2'    # MySQL 비밀번호
database = 'campus_24K_LI_p2_2'    # 사용할 데이터베이스 이름

# 연결 생성
connection = pymysql.connect(
    host=host,
    port=port,
    user=user,
    password=password,
    database=database
)

# app = Flask(__name__)

merged_cd111 = pd.merge(tb_study_review_keyword,tb_keyword, on='keyword_cd', how = "left")
merged_cd11 = merged_cd111.groupby("sview_cd").agg({
    "keyword_cd": lambda x: ', '.join(map(str, x)),  # keyword_cd를 쉼표로 구분된 문자열로 묶음
    "keyword_nm": lambda x: ', '.join(x)  # keyword_nm을 쉼표로 구분된 문자열로 묶음
}).reset_index()
merged_df101 = merged_cd11[["sview_cd", "keyword_cd", "keyword_nm"]]
merged_101 = merged_df101.groupby("sview_cd").agg({
    "keyword_cd": lambda x: ', '.join(map(str, x)),  # keyword_cd를 쉼표로 구분된 문자열로 묶음
    "keyword_nm": lambda x: ', '.join(x)  # keyword_nm을 쉼표로 구분된 문자열로 묶음
}).reset_index()
final_review1 = tb_study_review[["sview_cd", "study_cd", "user_id"]]
merged_5000 = pd.merge(merged_101,final_review1, on='sview_cd', how = "left")
tb_study1 = tb_study[["study_cd", "study_title"]]
merged_study_cd_nm = pd.merge(merged_5000,tb_study1, on='study_cd', how = "left")
tfidf = TfidfVectorizer(stop_words='english', lowercase = True) # 토큰화 전 소문자로 변환
tfidf_matrix = tfidf.fit_transform(merged_study_cd_nm['keyword_nm'])
tfidf_matrix
cosine_sim = linear_kernel(tfidf_matrix,tfidf_matrix)

def content_base (user_id,cosine_sim=cosine_sim):
  # 아이디 해당하는 인덱스 찾기
  index = merged_study_cd_nm[merged_study_cd_nm['user_id'] == user_id].index[0]

  # 해당 스터디에 대한 유사도 추출
  sim_scores = list(enumerate(cosine_sim[index]))

  # 유사도에 따라 스터디 정렬
  sim_scores = sorted(sim_scores,key=lambda x: x[1],reverse=True)

  # 유사도가 가장 높은 상위 20개 스터디 선택
  sim_top10 = sim_scores[1:21]

  # 유사도가 높은 스터디의 인덱스만 추출
  study_indices = [i[0] for i in sim_top10]

  # 인데스를 이용해 유사도가 높은 스터디 이름 출력 후 반환
  return merged_study_cd_nm['study_title'].iloc[study_indices]
print(content_base("minsu40@naver.com"))

# @app.route('/recommend', methods=['POST'])
# def recommend():
#     user_id = request.json.get('user_id')
#     if not user_id:
#         return jsonify({"error": "No user_id provided"}), 400
#     recommendations = content_base(user_id)
#     return jsonify({"recommendations": recommendations})

# if __name__ == '__main__':
#     app.run(host='0.0.0.0', port=5000)